{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos de Métodos de Optimización\n",
    "\n",
    "Notebook generado automáticamente a partir del script para comparar:\n",
    "- Método de máximo descenso con Armijo\n",
    "- Método de región de confianza con punto de Cauchy\n",
    "\n",
    "Ejemplo de uso en una celda de código:\n",
    "```python\n",
    "import experiments_mo_jupyter as mo\n",
    "df = mo.run_all()\n",
    "df\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f99403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script de experimentos numéricos para la función:\n",
    "    f(x, y) = (exp(x^2) + y^4) / (y^2 + 1)\n",
    "\n",
    "- Métodos:\n",
    "    * Máximo descenso con búsqueda de línea tipo Armijo\n",
    "    * Región de confianza con punto de Cauchy\n",
    "- Experimentos:\n",
    "    * 500 puntos iniciales ~ U([-100, 100]^2)\n",
    "    * Estadísticas globales para comparar convergencia de ambos métodos\n",
    "\n",
    "Salidas principales:\n",
    "    - random_results_500.csv     (resultados por punto inicial)\n",
    "    - random_stats_500.csv       (estadísticas globales por método)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import isfinite\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401  (para activar 3D)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Definición simbólica de f, gradiente y Hessiano\n",
    "# ============================================================\n",
    "\n",
    "x_sym, y_sym = sp.symbols('x y')\n",
    "f_sym = (sp.exp(x_sym**2) + y_sym**4) / (y_sym**2 + 1)\n",
    "\n",
    "grad_sym = [sp.diff(f_sym, x_sym), sp.diff(f_sym, y_sym)]\n",
    "hess_sym = sp.hessian(f_sym, (x_sym, y_sym))\n",
    "\n",
    "f_scalar = sp.lambdify((x_sym, y_sym), f_sym, 'numpy')\n",
    "grad_scalar = sp.lambdify((x_sym, y_sym), grad_sym, 'numpy')\n",
    "hess_scalar = sp.lambdify((x_sym, y_sym), hess_sym, 'numpy')\n",
    "\n",
    "\n",
    "def f_xy(x, y):\n",
    "    \"\"\"f(x, y) para escalares o arrays de numpy.\"\"\"\n",
    "    return f_scalar(x, y)\n",
    "\n",
    "\n",
    "def f_vec(x):\n",
    "    \"\"\"f para vector x = [x, y].\"\"\"\n",
    "    return float(f_scalar(x[0], x[1]))\n",
    "\n",
    "\n",
    "def grad_vec(x):\n",
    "    \"\"\"Gradiente como vector numpy de tamaño 2.\"\"\"\n",
    "    gx, gy = grad_scalar(x[0], x[1])\n",
    "    return np.array([float(gx), float(gy)], dtype=float)\n",
    "\n",
    "\n",
    "def hess_mat(x):\n",
    "    \"\"\"Hessiano 2x2 como matriz numpy.\"\"\"\n",
    "    H = np.array(hess_scalar(x[0], x[1]), dtype=float)\n",
    "    return H\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Utilidades numéricas\n",
    "# ============================================================\n",
    "\n",
    "def safe_f(x):\n",
    "    \"\"\"Evalúa f(x) y devuelve +inf si no es finita.\"\"\"\n",
    "    try:\n",
    "        val = f_vec(x)\n",
    "        if not np.isfinite(val):\n",
    "            return np.inf\n",
    "        return val\n",
    "    except Exception:\n",
    "        return np.inf\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Método de Máximo Descenso (Steepest Descent) con Armijo\n",
    "# ============================================================\n",
    "\n",
    "def steepest_descent(x0,\n",
    "                     alpha0=1.0,\n",
    "                     beta=0.5,\n",
    "                     sigma=1e-4,\n",
    "                     max_iters=200,\n",
    "                     tol_grad=1e-6):\n",
    "    \"\"\"\n",
    "    Máximo descenso con búsqueda de línea tipo Armijo.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    x0 : iterable de longitud 2\n",
    "        Punto inicial.\n",
    "    alpha0 : float\n",
    "        Paso inicial para la búsqueda de línea.\n",
    "    beta : float\n",
    "        Factor de reducción (0 < beta < 1).\n",
    "    sigma : float\n",
    "        Parámetro de Armijo (0 < sigma < 1).\n",
    "    max_iters : int\n",
    "        Máximo de iteraciones.\n",
    "    tol_grad : float\n",
    "        Tolerancia sobre la norma del gradiente.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    traj : lista de np.ndarray\n",
    "        Secuencia de puntos x_k.\n",
    "    hist : pd.DataFrame\n",
    "        Historial con columnas: k, fx, ng, alpha.\n",
    "    \"\"\"\n",
    "    xk = np.array(x0, dtype=float)\n",
    "    traj = [xk.copy()]\n",
    "    rows = []\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        fx = safe_f(xk)\n",
    "        gk = grad_vec(xk)\n",
    "        ng = np.linalg.norm(gk, ord=2)\n",
    "\n",
    "        rows.append({\"k\": k, \"fx\": fx, \"ng\": ng, \"alpha\": np.nan})\n",
    "\n",
    "        if not np.isfinite(fx) or ng < tol_grad:\n",
    "            break\n",
    "\n",
    "        pk = -gk\n",
    "        alpha = alpha0\n",
    "\n",
    "        # Búsqueda de línea de Armijo\n",
    "        while True:\n",
    "            x_new = xk + alpha * pk\n",
    "            f_new = safe_f(x_new)\n",
    "\n",
    "            if not np.isfinite(f_new):\n",
    "                # forzar reducción si explota numéricamente\n",
    "                alpha *= beta\n",
    "            else:\n",
    "                if f_new <= fx + sigma * alpha * np.dot(gk, pk):\n",
    "                    break\n",
    "                alpha *= beta\n",
    "\n",
    "            if alpha < 1e-12:\n",
    "                break\n",
    "\n",
    "        rows[-1][\"alpha\"] = alpha\n",
    "\n",
    "        if alpha < 1e-12 or not np.isfinite(f_new):\n",
    "            # No se pudo encontrar un paso aceptable\n",
    "            break\n",
    "\n",
    "        xk = x_new\n",
    "        traj.append(xk.copy())\n",
    "\n",
    "    hist = pd.DataFrame(rows)\n",
    "    return traj, hist\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Método de Región de Confianza (punto de Cauchy)\n",
    "# ============================================================\n",
    "\n",
    "def trust_region(x0,\n",
    "                 Delta0=1.0,\n",
    "                 Delta_max=100.0,\n",
    "                 eta=0.15,\n",
    "                 max_iters=200,\n",
    "                 tol_grad=1e-6):\n",
    "    \"\"\"\n",
    "    Método de región de confianza con punto de Cauchy.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    x0 : iterable de longitud 2\n",
    "        Punto inicial.\n",
    "    Delta0 : float\n",
    "        Radio inicial de la región de confianza.\n",
    "    Delta_max : float\n",
    "        Radio máximo permitido.\n",
    "    eta : float\n",
    "        Umbral de aceptación del paso (0 < eta < 0.25 típicamente).\n",
    "    max_iters : int\n",
    "        Máximo de iteraciones.\n",
    "    tol_grad : float\n",
    "        Tolerancia sobre la norma del gradiente.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    traj : lista de np.ndarray\n",
    "        Secuencia de puntos x_k.\n",
    "    hist : pd.DataFrame\n",
    "        Historial con columnas: k, fx, ng, Delta, rho.\n",
    "    \"\"\"\n",
    "    xk = np.array(x0, dtype=float)\n",
    "    Delta = Delta0\n",
    "    traj = [xk.copy()]\n",
    "    rows = []\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        fx = safe_f(xk)\n",
    "        gk = grad_vec(xk)\n",
    "        Hk = hess_mat(xk)\n",
    "        ng = np.linalg.norm(gk, ord=2)\n",
    "\n",
    "        rows.append({\"k\": k, \"fx\": fx, \"ng\": ng, \"Delta\": Delta, \"rho\": np.nan})\n",
    "\n",
    "        if not np.isfinite(fx) or ng < tol_grad:\n",
    "            break\n",
    "\n",
    "        if ng == 0:\n",
    "            break\n",
    "\n",
    "        # Punto de Cauchy\n",
    "        gHg = float(np.dot(gk, Hk @ gk))\n",
    "        if gHg <= 0:\n",
    "            tau = 1.0\n",
    "        else:\n",
    "            tau = min(ng**3 / (Delta * gHg), 1.0)\n",
    "\n",
    "        pk = -(tau * Delta / ng) * gk\n",
    "\n",
    "        f_trial = safe_f(xk + pk)\n",
    "\n",
    "        # Reducciones real y predicha\n",
    "        ared = fx - f_trial\n",
    "        pred = -(np.dot(gk, pk) + 0.5 * np.dot(pk, Hk @ pk))\n",
    "\n",
    "        if pred <= 0 or not np.isfinite(pred):\n",
    "            rho = -np.inf\n",
    "        else:\n",
    "            rho = ared / pred\n",
    "\n",
    "        rows[-1][\"rho\"] = rho\n",
    "\n",
    "        # Actualización de región de confianza\n",
    "        if rho < 0.25:\n",
    "            Delta *= 0.25\n",
    "        else:\n",
    "            if rho > 0.75 and np.isclose(np.linalg.norm(pk), Delta, rtol=1e-4, atol=1e-6):\n",
    "                Delta = min(2.0 * Delta, Delta_max)\n",
    "\n",
    "        # Aceptación / rechazo del paso\n",
    "        if rho > eta and np.isfinite(f_trial):\n",
    "            xk = xk + pk\n",
    "            traj.append(xk.copy())\n",
    "        # Si no se acepta, solo se reduce Delta y se reintenta en la próxima iteración\n",
    "\n",
    "    hist = pd.DataFrame(rows)\n",
    "    return traj, hist\n",
    "# ============================================================\n",
    "# Figuras para la función y la convergencia\n",
    "# ============================================================\n",
    "\n",
    "def plot_function_surface_and_contours(xmin=-3, xmax=3,\n",
    "                                       ymin=-3, ymax=3,\n",
    "                                       n_points=200,\n",
    "                                       fname_surface=\"fig_f_surface.png\",\n",
    "                                       fname_contours=\"fig_f_contours.png\"):\n",
    "    \"\"\"Genera una superficie 3D y un mapa de contornos de f en una ventana moderada.\"\"\"\n",
    "    xs = np.linspace(xmin, xmax, n_points)\n",
    "    ys = np.linspace(ymin, ymax, n_points)\n",
    "    X, Y = np.meshgrid(xs, ys)\n",
    "    Z = f_xy(X, Y)\n",
    "    # Evitar problemas de visualización con valores muy grandes\n",
    "    Z = np.where(np.isfinite(Z), Z, np.nan)\n",
    "\n",
    "    # Superficie 3D\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.plot_surface(X, Y, Z, linewidth=0, antialiased=True)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"f(x,y)\")\n",
    "    ax.set_title(\"Superficie de f(x,y)\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fname_surface, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Contornos en 2D (recortando valores muy grandes)\n",
    "    Z_clipped = Z.copy()\n",
    "    # Limitar a un percentil para ver mejor el valle\n",
    "    finite_vals = Z[np.isfinite(Z)]\n",
    "    if finite_vals.size > 0:\n",
    "        vmax = np.quantile(finite_vals, 0.95)\n",
    "        Z_clipped = np.clip(Z_clipped, None, vmax)\n",
    "\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    cs = ax2.contour(X, Y, Z_clipped, levels=20)\n",
    "    ax2.clabel(cs, inline=True, fontsize=8)\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_ylabel(\"y\")\n",
    "    ax2.set_title(\"Contornos de f(x,y)\")\n",
    "    fig2.tight_layout()\n",
    "    fig2.savefig(fname_contours, dpi=300)\n",
    "    plt.close(fig2)\n",
    "\n",
    "\n",
    "def plot_iterations_hist(csv_path=\"random_results_500.csv\",\n",
    "                         fname_hist_sd=\"fig_hist_sd_iters.png\",\n",
    "                         fname_hist_tr=\"fig_hist_tr_iters.png\"):\n",
    "    \"\"\"Histogramas del número de iteraciones para SD y TR.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # SD\n",
    "    fig_sd, ax_sd = plt.subplots()\n",
    "    ax_sd.hist(df[\"SD_iters\"], bins=range(1, 202, 5), edgecolor=\"black\")\n",
    "    ax_sd.set_xlabel(\"Iteraciones (SD)\")\n",
    "    ax_sd.set_ylabel(\"Frecuencia\")\n",
    "    ax_sd.set_title(\"Histograma de iteraciones - Steepest Descent\")\n",
    "    fig_sd.tight_layout()\n",
    "    fig_sd.savefig(fname_hist_sd, dpi=300)\n",
    "    plt.close(fig_sd)\n",
    "\n",
    "    # TR\n",
    "    fig_tr, ax_tr = plt.subplots()\n",
    "    ax_tr.hist(df[\"TR_iters\"], bins=range(1, 202, 5), edgecolor=\"black\")\n",
    "    ax_tr.set_xlabel(\"Iteraciones (TR)\")\n",
    "    ax_tr.set_ylabel(\"Frecuencia\")\n",
    "    ax_tr.set_title(\"Histograma de iteraciones - Trust Region\")\n",
    "    fig_tr.tight_layout()\n",
    "    fig_tr.savefig(fname_hist_tr, dpi=300)\n",
    "    plt.close(fig_tr)\n",
    "\n",
    "\n",
    "def plot_r0_vs_iters(csv_path=\"random_results_500.csv\",\n",
    "                     fname_scatter=\"fig_r0_vs_iters.png\"):\n",
    "    \"\"\"\n",
    "    Dispersión radio inicial ||x0|| vs iteraciones de SD y TR.\n",
    "    Ayuda a visualizar cómo empeora la convergencia al alejarse del valle.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    r0 = np.sqrt(df[\"x0_x\"]**2 + df[\"x0_y\"]**2)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(r0, df[\"SD_iters\"], s=10, alpha=0.6, label=\"SD\")\n",
    "    ax.scatter(r0, df[\"TR_iters\"], s=10, alpha=0.6, label=\"TR\")\n",
    "    ax.set_xlabel(r\"$\\|x_0\\|$\")\n",
    "    ax.set_ylabel(\"Iteraciones\")\n",
    "    ax.set_title(\"Iteraciones vs distancia inicial\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fname_scatter, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Experimentos aleatorios y estadísticas globales\n",
    "# ============================================================\n",
    "\n",
    "def run_random_experiments(n_samples=500,\n",
    "                           low=-100.0,\n",
    "                           high=100.0,\n",
    "                           seed=123,\n",
    "                           csv_path=\"random_results_500.csv\",\n",
    "                           stats_path=\"random_stats_500.csv\"):\n",
    "    \"\"\"\n",
    "    Corre SD y TR desde n_samples puntos iniciales ~ U([low, high]^2)\n",
    "    y guarda:\n",
    "      - resultados individuales en csv_path\n",
    "      - estadísticas globales en stats_path\n",
    "\n",
    "    Devuelve\n",
    "    --------\n",
    "    df : pd.DataFrame\n",
    "        Resultados por punto inicial.\n",
    "    stats : pd.DataFrame\n",
    "        Estadísticas globales por método.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    inits = rng.uniform(low, high, size=(n_samples, 2))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, x0 in enumerate(inits):\n",
    "        x0_tuple = (float(x0[0]), float(x0[1]))\n",
    "\n",
    "        # ------- Máximo descenso -------\n",
    "        traj_sd, hist_sd = steepest_descent(x0_tuple, alpha0=1.0)\n",
    "        if len(hist_sd) > 0:\n",
    "            sd_last = hist_sd.iloc[-1]\n",
    "            sd_iters = int(sd_last[\"k\"]) + 1\n",
    "            sd_fx = float(sd_last[\"fx\"])\n",
    "            sd_ng = float(sd_last[\"ng\"])\n",
    "            sd_x_final = traj_sd[-1].tolist()\n",
    "        else:\n",
    "            sd_iters = np.nan\n",
    "            sd_fx = np.nan\n",
    "            sd_ng = np.nan\n",
    "            sd_x_final = [np.nan, np.nan]\n",
    "\n",
    "        # ------- Región de confianza -------\n",
    "        traj_tr, hist_tr = trust_region(x0_tuple, Delta0=1.0)\n",
    "        if len(hist_tr) > 0:\n",
    "            tr_last = hist_tr.iloc[-1]\n",
    "            tr_iters = int(tr_last[\"k\"]) + 1\n",
    "            tr_fx = float(tr_last[\"fx\"])\n",
    "            tr_ng = float(tr_last[\"ng\"])\n",
    "            tr_x_final = traj_tr[-1].tolist()\n",
    "        else:\n",
    "            tr_iters = np.nan\n",
    "            tr_fx = np.nan\n",
    "            tr_ng = np.nan\n",
    "            tr_x_final = [np.nan, np.nan]\n",
    "\n",
    "        results.append({\n",
    "            \"sample_id\": i,\n",
    "            \"x0_x\": x0_tuple[0],\n",
    "            \"x0_y\": x0_tuple[1],\n",
    "            \"SD_iters\": sd_iters,\n",
    "            \"TR_iters\": tr_iters,\n",
    "            \"SD_fx_final\": sd_fx,\n",
    "            \"TR_fx_final\": tr_fx,\n",
    "            \"SD_grad_norm_final\": sd_ng,\n",
    "            \"TR_grad_norm_final\": tr_ng,\n",
    "            \"SD_x_final\": sd_x_final,\n",
    "            \"TR_x_final\": tr_x_final,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # ---------- Estadísticas globales para análisis de convergencia ----------\n",
    "    sd_cols = [\"SD_iters\", \"SD_fx_final\", \"SD_grad_norm_final\"]\n",
    "    tr_cols = [\"TR_iters\", \"TR_fx_final\", \"TR_grad_norm_final\"]\n",
    "\n",
    "    sd_stats = df[sd_cols].agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "    tr_stats = df[tr_cols].agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "\n",
    "    sd_stats.columns = [\"iters\", \"f_final\", \"grad_norm_final\"]\n",
    "    tr_stats.columns = [\"iters\", \"f_final\", \"grad_norm_final\"]\n",
    "\n",
    "    stats = pd.concat(\n",
    "        {\"SteepestDescent\": sd_stats, \"TrustRegion\": tr_stats},\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    stats.to_csv(stats_path)\n",
    "\n",
    "    print(\"\\n=== Estadísticas globales ({} muestras) ===\".format(n_samples))\n",
    "    print(stats)\n",
    "\n",
    "    return df, stats\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Punto de entrada principal\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ejecutar experimentos aleatorios\n",
    "    df_rand, stats_rand = run_random_experiments(\n",
    "        n_samples=500,\n",
    "        low=-100.0,\n",
    "        high=100.0,\n",
    "        seed=123,\n",
    "        csv_path=\"random_results_500.csv\",\n",
    "        stats_path=\"random_stats_500.csv\",\n",
    "    )\n",
    "\n",
    "    # Generar figuras para incluir en el informe\n",
    "    plot_function_surface_and_contours()\n",
    "    plot_iterations_hist(\"random_results_500.csv\")\n",
    "    plot_r0_vs_iters(\"random_results_500.csv\")\n",
    "\n",
    "    print(\"\\nFiguras guardadas como:\")\n",
    "    print(\" - fig_f_surface.png\")\n",
    "    print(\" - fig_f_contours.png\")\n",
    "    print(\" - fig_hist_sd_iters.png\")\n",
    "    print(\" - fig_hist_tr_iters.png\")\n",
    "    print(\" - fig_r0_vs_iters.png\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
