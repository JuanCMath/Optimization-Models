{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Experimentos de M\u00e9todos de Optimizaci\u00f3n\n", "\n", "Notebook generado autom\u00e1ticamente a partir del script para comparar:\n", "- M\u00e9todo de m\u00e1ximo descenso con Armijo\n", "- M\u00e9todo de regi\u00f3n de confianza con punto de Cauchy\n", "\n", "Ejemplo de uso en una celda de c\u00f3digo:\n", "```python\n", "import experiments_mo_jupyter as mo\n", "df = mo.run_all()\n", "df\n", "```\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["\n", "#!/usr/bin/env python3\n", "# -*- coding: utf-8 -*-\n", "\"\"\"\n", "Script pensado para usarse desde Jupyter Notebook.\n", "\n", "- Objetivo: f(x,y) = (exp(x^2) + y^4) / (y^2 + 1)\n", "- M\u00e9todos: M\u00e1ximo descenso (Armijo) y Regi\u00f3n de confianza (punto de Cauchy)\n", "- Salidas:\n", "    * Figuras (se guardan como PNG y tambi\u00e9n se muestran en Jupyter)\n", "    * CSV con resultados\n", "    * Tabla en formato LaTeX\n", "\n", "Uso t\u00edpico en Jupyter:\n", "\n", "    import experiments_mo_jupyter as mo\n", "    df = mo.run_all()\n", "    df  # ver tabla de resumen\n", "\n", "Tambi\u00e9n puedes llamar directamente a steepest_descent, trust_region, etc.\n", "\"\"\"\n", "\n", "import numpy as np\n", "import sympy as sp\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "from math import isfinite\n", "\n", "# ======================\n", "# Definiciones simb\u00f3licas de la funci\u00f3n objetivo y sus derivadas\n", "# ======================\n", "\n", "# Definir variables simb\u00f3licas\n", "x, y = sp.symbols('x y', real=True)\n", "\n", "# Funci\u00f3n objetivo: f(x,y) = (exp(x**2) + y**4) / (y**2 + 1)\n", "f_expr = (sp.exp(x**2) + y**4) / (y**2 + 1)\n", "\n", "# Calcular gradiente simb\u00f3licamente\n", "grad_expr = [sp.diff(f_expr, v) for v in (x, y)]\n", "\n", "# Calcular matriz Hessiana simb\u00f3licamente\n", "hess_expr = sp.hessian(f_expr, (x, y))\n", "\n", "# Convertir expresiones simb\u00f3licas a funciones num\u00e9ricas usando lambdify\n", "f = sp.lambdify((x, y), f_expr, 'numpy')        # Funci\u00f3n objetivo\n", "grad = sp.lambdify((x, y), grad_expr, 'numpy')  # Gradiente\n", "hess = sp.lambdify((x, y), hess_expr, 'numpy')  # Hessiana\n", "\n", "# ---------- Armijo backtracking ----------\n", "def armijo(f, grad, xk, dk, alpha0=1.0, c=1e-4, tau=0.5, max_iter=30):\n", "    \"\"\"\n", "    Implementa la b\u00fasqueda de l\u00ednea con condici\u00f3n de Armijo.\n", "\n", "    Encuentra un tama\u00f1o de paso que satisface la condici\u00f3n de Armijo:\n", "    f(xk + alpha*dk) <= f(xk) + c*alpha*grad(xk)^T*dk\n", "    \"\"\"\n", "    fx = f(*xk)\n", "    gk = np.array(grad(*xk), dtype=float).reshape(-1)\n", "\n", "    # derivada direccional\n", "    dphi0 = gk @ dk\n", "\n", "    alpha = alpha0\n", "    for _ in range(max_iter):\n", "        x_new = xk + alpha * dk\n", "        if f(*x_new) <= fx + c * alpha * dphi0:\n", "            return alpha\n", "        alpha *= tau\n", "\n", "    return alpha\n", "\n", "# ---------- Steepest Descent ----------\n", "def steepest_descent(x0, max_iter=200, tol=1e-8, alpha0=1.0):\n", "    \"\"\"\n", "    M\u00e9todo de m\u00e1ximo descenso con b\u00fasqueda de l\u00ednea Armijo.\n", "    Devuelve la trayectoria y un DataFrame con el historial.\n", "    \"\"\"\n", "    xk = np.array(x0, dtype=float)\n", "    traj = [xk.copy()]\n", "    hist = []\n", "\n", "    for k in range(max_iter):\n", "        gk = np.array(grad(*xk), dtype=float).reshape(-1)\n", "        ng = np.linalg.norm(gk)\n", "        fx = f(*xk)\n", "\n", "        hist.append(dict(\n", "            k=k,\n", "            fx=float(fx),\n", "            ng=float(ng),\n", "            x=float(xk[0]),\n", "            y=float(xk[1])\n", "        ))\n", "\n", "        if not isfinite(fx) or not np.isfinite(gk).all() or ng < tol:\n", "            break\n", "\n", "        dk = -gk\n", "        alpha = armijo(f, grad, xk, dk, alpha0=alpha0)\n", "        xk = xk + alpha * dk\n", "        traj.append(xk.copy())\n", "\n", "    return np.array(traj), pd.DataFrame(hist)\n", "\n", "# ---------- Trust Region (Cauchy point) ----------\n", "def trust_region(x0, max_iter=200, tol=1e-8, Delta0=1.0, eta=0.1):\n", "    \"\"\"\n", "    M\u00e9todo de regi\u00f3n de confianza usando el punto de Cauchy.\n", "    Devuelve la trayectoria y un DataFrame con el historial.\n", "    \"\"\"\n", "    xk = np.array(x0, dtype=float)\n", "    Delta = Delta0\n", "    traj = [xk.copy()]\n", "    hist = []\n", "\n", "    for k in range(max_iter):\n", "        gk = np.array(grad(*xk), dtype=float).reshape(-1)\n", "        Bk = np.array(hess(*xk), dtype=float)\n", "        fx = f(*xk)\n", "        ng = np.linalg.norm(gk)\n", "\n", "        hist.append(dict(\n", "            k=k,\n", "            fx=float(fx),\n", "            ng=float(ng),\n", "            Delta=float(Delta),\n", "            x=float(xk[0]),\n", "            y=float(xk[1])\n", "        ))\n", "\n", "        if (not isfinite(fx) or\n", "            not np.isfinite(gk).all() or\n", "            not np.isfinite(Bk).all() or\n", "            ng < tol):\n", "            break\n", "\n", "        gBg = float(gk @ (Bk @ gk))\n", "\n", "        if gBg <= 0:\n", "            tau = 1.0\n", "        else:\n", "            tau = min(ng**3 / (Delta * gBg), 1.0)\n", "\n", "        pk = -(tau * Delta / ng) * gk\n", "\n", "        mk0 = fx\n", "        mkp = fx + gk @ pk + 0.5 * pk @ (Bk @ pk)\n", "        pred_red = mk0 - mkp\n", "\n", "        xtrial = xk + pk\n", "        ared = fx - f(*xtrial)\n", "\n", "        rho = ared / pred_red if pred_red != 0 else -np.inf\n", "\n", "        if rho < 0.25:\n", "            Delta *= 0.25\n", "        else:\n", "            if rho > 0.75 and abs(np.linalg.norm(pk) - Delta) < 1e-12:\n", "                Delta = min(2 * Delta, 100.0)\n", "\n", "        if rho > eta:\n", "            xk = xtrial\n", "            traj.append(xk.copy())\n", "\n", "    return np.array(traj), pd.DataFrame(hist)\n", "\n", "# ---------- Plot helpers ----------\n", "def plot_surface_and_contours(xlim=(-3, 3), ylim=(-3, 3), prefix=\"fig\"):\n", "    \"\"\"\n", "    Gr\u00e1ficos de contornos y superficie 3D de la funci\u00f3n objetivo.\n", "    Guarda PNG y tambi\u00e9n muestra las figuras (\u00fatil en Jupyter).\n", "    \"\"\"\n", "    X = np.linspace(*xlim, 300)\n", "    Y = np.linspace(*ylim, 300)\n", "    XX, YY = np.meshgrid(X, Y)\n", "    ZZ = f(XX, YY)\n", "\n", "    # Contornos\n", "    plt.figure(figsize=(7, 6))\n", "    cs = plt.contour(XX, YY, ZZ, levels=30)\n", "    plt.clabel(cs, inline=1, fontsize=8)\n", "    plt.xlabel(\"x\")\n", "    plt.ylabel(\"y\")\n", "    plt.title(\"Contornos de f(x,y)\")\n", "    plt.tight_layout()\n", "    plt.savefig(prefix + \"_contours.png\", dpi=160)\n", "    plt.show()\n", "    plt.close()\n", "\n", "    # Superficie 3D\n", "    from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n", "    fig = plt.figure(figsize=(7, 6))\n", "    ax = fig.add_subplot(111, projection='3d')\n", "\n", "    Xs = np.linspace(*xlim, 100)\n", "    Ys = np.linspace(*ylim, 100)\n", "    XXs, YYs = np.meshgrid(Xs, Ys)\n", "    ZZs = f(XXs, YYs)\n", "\n", "    ax.plot_surface(XXs, YYs, ZZs, linewidth=0, antialiased=False)\n", "    ax.set_xlabel(\"x\")\n", "    ax.set_ylabel(\"y\")\n", "    ax.set_zlabel(\"f\")\n", "    ax.set_title(\"Superficie de f(x,y)\")\n", "    plt.tight_layout()\n", "    plt.savefig(prefix + \"_surface.png\", dpi=160)\n", "    plt.show()\n", "    plt.close()\n", "\n", "def plot_trajectories_over_contour(trajs, title, fname):\n", "    \"\"\"\n", "    Grafica las trayectorias de optimizaci\u00f3n sobre los contornos de la funci\u00f3n.\n", "    Guarda PNG y muestra la figura.\n", "    \"\"\"\n", "    X = np.linspace(-3, 3, 300)\n", "    Y = np.linspace(-3, 3, 300)\n", "    XX, YY = np.meshgrid(X, Y)\n", "    ZZ = f(XX, YY)\n", "\n", "    plt.figure(figsize=(7, 6))\n", "    cs = plt.contour(XX, YY, ZZ, levels=30)\n", "    plt.clabel(cs, inline=1, fontsize=8)\n", "\n", "    for x0, T in trajs.items():\n", "        plt.plot(T[:, 0], T[:, 1],\n", "                 marker='o', markersize=3, linewidth=1.2,\n", "                 label=f\"init {x0}\")\n", "        plt.scatter([T[0, 0]], [T[0, 1]], marker='x')\n", "        plt.scatter([T[-1, 0]], [T[-1, 1]], marker='*')\n", "\n", "    plt.legend()\n", "    plt.xlabel(\"x\")\n", "    plt.ylabel(\"y\")\n", "    plt.title(title)\n", "    plt.tight_layout()\n", "    plt.savefig(fname, dpi=160)\n", "    plt.show()\n", "    plt.close()\n", "\n", "def plot_convergence(hist_map, method_name, fname):\n", "    \"\"\"\n", "    Grafica la convergencia de f(x_k) para cada punto inicial.\n", "    Guarda PNG y muestra la figura.\n", "    \"\"\"\n", "    plt.figure(figsize=(7, 5))\n", "\n", "    for x0, hist in hist_map.items():\n", "        plt.plot(hist['k'], hist['fx'], label=f\"f(x_k), init {x0}\")\n", "\n", "    plt.xlabel(\"k\")\n", "    plt.ylabel(\"f(x_k)\")\n", "    plt.title(f\"Convergencia de f - {method_name}\")\n", "    plt.legend()\n", "    plt.tight_layout()\n", "    plt.savefig(fname, dpi=160)\n", "    plt.show()\n", "    plt.close()\n", "\n", "# ---------- Save LaTeX table ----------\n", "def save_table_tex(df, tex_path):\n", "    \"\"\"\n", "    Guarda una tabla comparativa en formato LaTeX.\n", "    \"\"\"\n", "    tbl = df.copy()\n", "\n", "    for col in ['SD_fx_final', 'TR_fx_final',\n", "                'SD_grad_norm_final', 'TR_grad_norm_final']:\n", "        if col in tbl.columns:\n", "            tbl[col] = tbl[col].map(\n", "                lambda v: f\"{v:.6g}\" if pd.notnull(v) else \"--\"\n", "            )\n", "\n", "    tbl['SD_x_final'] = tbl['SD_x_final'].map(\n", "        lambda v: f\"({v[0]:.4g},{v[1]:.4g})\"\n", "        if isinstance(v, (list, tuple)) else \"--\"\n", "    )\n", "    tbl['TR_x_final'] = tbl['TR_x_final'].map(\n", "        lambda v: f\"({v[0]:.4g},{v[1]:.4g})\"\n", "        if isinstance(v, (list, tuple)) else \"--\"\n", "    )\n", "\n", "    cols = [\"x0\", \"SD_iters\", \"TR_iters\", \"SD_fx_final\", \"TR_fx_final\",\n", "            \"SD_grad_norm_final\", \"TR_grad_norm_final\",\n", "            \"SD_x_final\", \"TR_x_final\"]\n", "\n", "    header = \" & \".join([\n", "        \"$x_0$\", \"SD iters\", \"TR iters\", \"SD $f(x_k)$\", \"TR $f(x_k)$\",\n", "        \"SD $\\\\|\\\\nabla f\\\\|$\", \"TR $\\\\|\\\\nabla f\\\\|$\", \"SD $x_k$\", \"TR $x_k$\"\n", "    ]) + \" \\\\\"\n", "\n", "    lines = [\n", "        \"\\\\begin{tabular}{lrrrrrrrr}\",\n", "        \"\\\\toprule\",\n", "        header,\n", "        \"\\\\midrule\"\n", "    ]\n", "\n", "    for _, row in tbl[cols].iterrows():\n", "        x0s = f\"({row['x0'][0]:.2g},{row['x0'][1]:.2g})\"\n", "        line = \" & \".join([\n", "            x0s,\n", "            str(row['SD_iters']), str(row['TR_iters']),\n", "            row['SD_fx_final'], row['TR_fx_final'],\n", "            row['SD_grad_norm_final'], row['TR_grad_norm_final'],\n", "            row['SD_x_final'], row['TR_x_final']\n", "        ]) + \" \\\\\"\n", "        lines.append(line)\n", "\n", "    lines += [\"\\\\bottomrule\", \"\\\\end{tabular}\"]\n", "\n", "    with open(tex_path, \"w\", encoding=\"utf-8\") as ft:\n", "        ft.write(\"\\n\".join(lines))\n", "\n", "# ---------- Experiments ----------\n", "def run_all():\n", "    \"\"\"\n", "    Ejecuta los experimentos de comparaci\u00f3n desde varios puntos iniciales,\n", "    genera figuras, CSV y tabla LaTeX, y devuelve un DataFrame con el resumen.\n", "    \"\"\"\n", "    inits = [(2.0, 2.0), (-2.0, 1.0), (0.5, -1.5)]\n", "\n", "    results = []\n", "    traj_sd_map, traj_tr_map = {}, {}\n", "    hist_sd_map, hist_tr_map = {}, {}\n", "\n", "    for x0 in inits:\n", "        traj_sd, hist_sd = steepest_descent(x0, alpha0=1.0)\n", "        traj_tr, hist_tr = trust_region(x0, Delta0=1.0)\n", "\n", "        traj_sd_map[x0], traj_tr_map[x0] = traj_sd, traj_tr\n", "        hist_sd_map[x0], hist_tr_map[x0] = hist_sd, hist_tr\n", "\n", "        if len(hist_sd):\n", "            sd_last = hist_sd.iloc[-1]\n", "        else:\n", "            sd_last = {'fx': np.nan, 'ng': np.nan}\n", "\n", "        if len(hist_tr):\n", "            tr_last = hist_tr.iloc[-1]\n", "        else:\n", "            tr_last = {'fx': np.nan, 'ng': np.nan}\n", "\n", "        results.append({\n", "            'x0': x0,\n", "            'SD_iters': len(hist_sd),\n", "            'TR_iters': len(hist_tr),\n", "            'SD_fx_final': float(sd_last['fx']) if len(hist_sd) else np.nan,\n", "            'TR_fx_final': float(tr_last['fx']) if len(hist_tr) else np.nan,\n", "            'SD_grad_norm_final': float(sd_last['ng']) if len(hist_sd) else np.nan,\n", "            'TR_grad_norm_final': float(tr_last['ng']) if len(hist_tr) else np.nan,\n", "            'SD_x_final': traj_sd[-1].tolist() if len(traj_sd) else [np.nan, np.nan],\n", "            'TR_x_final': traj_tr[-1].tolist() if len(traj_tr) else [np.nan, np.nan],\n", "        })\n", "\n", "    comparison_df = pd.DataFrame(results)\n", "    comparison_df.to_csv(\"comparison_results.csv\", index=False)\n", "\n", "    # Figuras (se muestran en Jupyter y se guardan en PNG)\n", "    plot_surface_and_contours()\n", "    plot_trajectories_over_contour(\n", "        traj_sd_map,\n", "        \"Trayectorias - M\u00e1ximo descenso (Armijo)\",\n", "        \"fig_traj_sd.png\"\n", "    )\n", "    plot_trajectories_over_contour(\n", "        traj_tr_map,\n", "        \"Trayectorias - Regi\u00f3n de confianza (punto de Cauchy)\",\n", "        \"fig_traj_tr.png\"\n", "    )\n", "    plot_convergence(hist_sd_map, \"M\u00e1ximo descenso\", \"fig_conv_sd.png\")\n", "    plot_convergence(hist_tr_map, \"Regi\u00f3n de confianza\", \"fig_conv_tr.png\")\n", "\n", "    # Tabla LaTeX\n", "    save_table_tex(comparison_df, \"comparison_table.tex\")\n", "\n", "    return comparison_df\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    # Si ejecutas el archivo como script (python experiments_mo_jupyter.py)\n", "    df = run_all()\n", "    print(df)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}